{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we aggregate the model stats for our rebuttal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "def find_stats_files(base_dataset, base_model, models_dir=\"models\"):\n",
    "    \"\"\"\n",
    "    Find all stats.csv files for a given base dataset and model combination.\n",
    "    \n",
    "    Args:\n",
    "        base_dataset: e.g., \"base_cinic10\", \"base_cifar20\"\n",
    "        base_model: e.g., \"cifar-resnet-18\", \"cifar-resnet-50\", \"cifar-vit\"\n",
    "        models_dir: Root directory containing the models\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (cls_drop_string, file_path)\n",
    "    \"\"\"\n",
    "    # Pattern to match the directory structure\n",
    "    pattern = f\"{models_dir}/mia/{base_dataset}/*/{base_model}/*/*/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_*/predictions/stats.csv\"\n",
    "    \n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    # Extract cls_drop string from each file path\n",
    "    cls_drop_files = []\n",
    "    for file_path in files:\n",
    "        # Extract cls_drop string from path\n",
    "        parts = file_path.split('/')\n",
    "        cls_drop_part = [part for part in parts if part.startswith('cls_drop_')]\n",
    "        if cls_drop_part:\n",
    "            cls_drop_str = cls_drop_part[0].split('_')[-1]\n",
    "            cls_drop_files.append((cls_drop_str, file_path))\n",
    "    \n",
    "    # Sort by cls_drop string\n",
    "    cls_drop_files.sort(key=lambda x: [int(n) for n in x[0].split(',')])\n",
    "    return cls_drop_files\n",
    "\n",
    "def load_and_aggregate_data(cls_drop_files):\n",
    "    \"\"\"\n",
    "    Load all stats.csv files and aggregate into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        cls_drop_files: List of tuples (cls_drop_string, file_path)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with aggregated data\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for cls_drop_str, file_path in cls_drop_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['cls_drop'] = cls_drop_str\n",
    "            all_data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read {file_path}: {e}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(\"No valid stats.csv files found!\")\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def create_metric_table(df, qmia_metric, baseline_metric, metric_name):\n",
    "    \"\"\"\n",
    "    Create a table for a specific metric showing QMIA and Baseline values.\n",
    "    \n",
    "    Args:\n",
    "        df: Aggregated DataFrame\n",
    "        qmia_metric: Column name for QMIA metric\n",
    "        baseline_metric: Column name for Baseline metric\n",
    "        metric_name: Human-readable metric name\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with the metric table\n",
    "    \"\"\"\n",
    "    # Pivot table with cls_drop as columns and dataset_type as rows\n",
    "    qmia_table = df.pivot(index='dataset_type', columns='cls_drop', values=qmia_metric)\n",
    "    baseline_table = df.pivot(index='dataset_type', columns='cls_drop', values=baseline_metric)\n",
    "    \n",
    "    # Create multi-level columns\n",
    "    qmia_cols = pd.MultiIndex.from_product([['QMIA'], qmia_table.columns], \n",
    "                                           names=['Method', 'cls_drop'])\n",
    "    baseline_cols = pd.MultiIndex.from_product([['Baseline'], baseline_table.columns], \n",
    "                                               names=['Method', 'cls_drop'])\n",
    "    \n",
    "    qmia_table.columns = qmia_cols\n",
    "    baseline_table.columns = baseline_cols\n",
    "    \n",
    "    # Combine tables\n",
    "    result_table = pd.concat([qmia_table, baseline_table], axis=1)\n",
    "    \n",
    "    # Sort columns by cls_drop numbers within each method\n",
    "    result_table = result_table.reindex(sorted(result_table.columns, key=lambda x: [int(n) for n in x[1].split(',')]), axis=1)\n",
    "    \n",
    "    return result_table\n",
    "\n",
    "def format_table_for_display(table, metric_name):\n",
    "    \"\"\"Format table with proper rounding and add a title.\"\"\"\n",
    "    # Round to 4 decimal places for readability\n",
    "    formatted_table = table.round(4)\n",
    "    \n",
    "    # Add a descriptive name\n",
    "    formatted_table.index.name = 'Dataset Type'\n",
    "    \n",
    "    return formatted_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stats files for base_cifar20 with cifar-resnet-50-dp_dp_eps1.0_delta1e-10_clip1.0...\n",
      "Found 3 stats files:\n",
      "  cls_drop_0: ../models/mia/base_cifar20/0_16/cifar-resnet-50-dp_dp_eps1.0_delta1e-10_clip1.0/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_0/predictions/stats.csv\n",
      "  cls_drop_1: ../models/mia/base_cifar20/0_16/cifar-resnet-50-dp_dp_eps1.0_delta1e-10_clip1.0/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_1/predictions/stats.csv\n",
      "  cls_drop_2: ../models/mia/base_cifar20/0_16/cifar-resnet-50-dp_dp_eps1.0_delta1e-10_clip1.0/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_2/predictions/stats.csv\n",
      "\n",
      "Loading and aggregating data...\n",
      "\n",
      "Creating AUC table...\n",
      "\n",
      "Creating TPR_at_1pct_FPR table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2014758/896500810.py:61: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  stacked_table = table.loc[['out_of_distribution']].stack(level='Method').reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls_drop</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>01</th>\n",
       "      <th>23</th>\n",
       "      <th>45</th>\n",
       "      <th>67</th>\n",
       "      <th>89</th>\n",
       "      <th>01234</th>\n",
       "      <th>56789</th>\n",
       "      <th>0123456789</th>\n",
       "      <th>10111213141516171819</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_type</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">out_of_distribution</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.688</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMIA</th>\n",
       "      <td>0.707</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cls_drop                          0      1      2   3   4   5   6   7   8   9  \\\n",
       "dataset_type        Method                                                      \n",
       "out_of_distribution Baseline  0.688  0.696  0.589 NaN NaN NaN NaN NaN NaN NaN   \n",
       "                    QMIA      0.707  0.711  0.609 NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "cls_drop                      01  23  45  67  89  01234  56789  0123456789  \\\n",
       "dataset_type        Method                                                   \n",
       "out_of_distribution Baseline NaN NaN NaN NaN NaN    NaN    NaN         NaN   \n",
       "                    QMIA     NaN NaN NaN NaN NaN    NaN    NaN         NaN   \n",
       "\n",
       "cls_drop                      10111213141516171819  \n",
       "dataset_type        Method                          \n",
       "out_of_distribution Baseline                   NaN  \n",
       "                    QMIA                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2014758/896500810.py:61: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  stacked_table = table.loc[['out_of_distribution']].stack(level='Method').reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls_drop</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>01</th>\n",
       "      <th>23</th>\n",
       "      <th>45</th>\n",
       "      <th>67</th>\n",
       "      <th>89</th>\n",
       "      <th>01234</th>\n",
       "      <th>56789</th>\n",
       "      <th>0123456789</th>\n",
       "      <th>10111213141516171819</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_type</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">out_of_distribution</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMIA</th>\n",
       "      <td>0.67</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cls_drop                         0     1     2   3   4   5   6   7   8   9  \\\n",
       "dataset_type        Method                                                   \n",
       "out_of_distribution Baseline  2.00  0.49  0.40 NaN NaN NaN NaN NaN NaN NaN   \n",
       "                    QMIA      0.67  1.71  2.65 NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "cls_drop                      01  23  45  67  89  01234  56789  0123456789  \\\n",
       "dataset_type        Method                                                   \n",
       "out_of_distribution Baseline NaN NaN NaN NaN NaN    NaN    NaN         NaN   \n",
       "                    QMIA     NaN NaN NaN NaN NaN    NaN    NaN         NaN   \n",
       "\n",
       "cls_drop                      10111213141516171819  \n",
       "dataset_type        Method                          \n",
       "out_of_distribution Baseline                   NaN  \n",
       "                    QMIA                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = type('Args', (), {\n",
    "    'base_dataset': 'base_cifar20',\n",
    "    'base_model': 'cifar-resnet-50-dp_dp_eps1.0_delta1e-10_clip1.0',\n",
    "    'models_dir': '../models',\n",
    "    'output_dir': '../rebuttal_outputs'\n",
    "})()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(args.output_dir)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Find all stats files for the given dataset and model\n",
    "print(f\"Finding stats files for {args.base_dataset} with {args.base_model}...\")\n",
    "cls_drop_files = find_stats_files(args.base_dataset, args.base_model, args.models_dir)\n",
    "\n",
    "if not cls_drop_files:\n",
    "    print(f\"No stats.csv files found for {args.base_dataset}/{args.base_model}\")\n",
    "\n",
    "print(f\"Found {len(cls_drop_files)} stats files:\")\n",
    "for cls_drop_num, file_path in cls_drop_files:\n",
    "    print(f\"  cls_drop_{cls_drop_num}: {file_path}\")\n",
    "\n",
    "# Load and aggregate data\n",
    "print(\"\\nLoading and aggregating data...\")\n",
    "df = load_and_aggregate_data(cls_drop_files)\n",
    "\n",
    "# Create output filename prefix\n",
    "output_prefix = f\"{args.base_dataset}_{args.base_model.replace('-', '_')}\"\n",
    "\n",
    "# Create the three metric tables\n",
    "metrics = [\n",
    "    ('qmia_auc', 'baseline_auc', 'AUC'),\n",
    "    ('qmia_tpr_at_fpr_1%', 'baseline_tpr_at_fpr_1%', 'TPR_at_1pct_FPR'),\n",
    "    # ('qmia_tpr_at_fpr_0.1%', 'baseline_tpr_at_fpr_0.1%', 'TPR_at_0.1pct_FPR')\n",
    "]\n",
    "\n",
    "tables = []\n",
    "\n",
    "for qmia_metric, baseline_metric, metric_name in metrics:\n",
    "    print(f\"\\nCreating {metric_name} table...\")\n",
    "    \n",
    "    # Create the table\n",
    "    table = create_metric_table(df, qmia_metric, baseline_metric, metric_name)\n",
    "    \n",
    "    # # Save to CSV\n",
    "    # output_file = output_dir / f\"{output_prefix}_{metric_name.lower()}.csv\"\n",
    "    # formatted_table.to_csv(output_file)\n",
    "    # print(f\"Saved {metric_name} table to: {output_file}\")\n",
    "\n",
    "    tables.append(table)\n",
    "\n",
    "for (qmia_metric, baseline_metric, metric_name), table in zip(metrics, tables):\n",
    "    if \"TPR\" in metric_name:\n",
    "        table *= 100\n",
    "        table[numeric_cols] = table[numeric_cols].round(2)\n",
    "    else:\n",
    "        table = table.round(3)\n",
    "    numeric_cols = table.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Stack Method annotations as rows\n",
    "    stacked_table = table.loc[['out_of_distribution']].stack(level='Method').reset_index()\n",
    "    stacked_table = stacked_table.rename(columns={'level_1': 'Method'})\n",
    "    stacked_table = stacked_table.set_index(['dataset_type', 'Method'])\n",
    "    \n",
    "    # Define the desired column order\n",
    "    col_order = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "                 '01', '23', '45', '67', '89', '01234', '56789', \n",
    "                 '0123456789', '10111213141516171819']\n",
    "    \n",
    "    # Reorder columns, keeping dataset_type and Method as index\n",
    "    stacked_table = stacked_table.reindex(columns=col_order)\n",
    "    display(stacked_table)\n",
    "\n",
    "# # Save raw aggregated data as well\n",
    "# raw_output_file = output_dir / f\"{output_prefix}_raw_data.csv\"\n",
    "# df.to_csv(raw_output_file, index=False)\n",
    "# print(f\"\\nSaved raw aggregated data to: {raw_output_file}\")\n",
    "\n",
    "# print(f\"\\nAll outputs saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
