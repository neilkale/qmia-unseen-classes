{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we aggregate the model stats for our rebuttal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "def find_stats_files(base_dataset, base_model, models_dir=\"models\"):\n",
    "    \"\"\"\n",
    "    Find all stats.csv files for a given base dataset and model combination.\n",
    "    \n",
    "    Args:\n",
    "        base_dataset: e.g., \"base_cinic10\", \"base_cifar20\"\n",
    "        base_model: e.g., \"cifar-resnet-18\", \"cifar-resnet-50\", \"cifar-vit\"\n",
    "        models_dir: Root directory containing the models\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (cls_drop_string, file_path)\n",
    "    \"\"\"\n",
    "    # Pattern to match the directory structure\n",
    "    pattern = f\"{models_dir}/mia/{base_dataset}/*/{base_model}/*/*/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_*/predictions/stats.csv\"\n",
    "    \n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    # Extract cls_drop string from each file path\n",
    "    cls_drop_files = []\n",
    "    for file_path in files:\n",
    "        # Extract cls_drop string from path\n",
    "        parts = file_path.split('/')\n",
    "        cls_drop_part = [part for part in parts if part.startswith('cls_drop_')]\n",
    "        if cls_drop_part:\n",
    "            cls_drop_str = cls_drop_part[0].split('_')[-1]\n",
    "            cls_drop_files.append((cls_drop_str, file_path))\n",
    "    \n",
    "    # Sort by cls_drop string\n",
    "    cls_drop_files.sort(key=lambda x: [int(n) for n in x[0].split(',')])\n",
    "    return cls_drop_files\n",
    "\n",
    "def load_and_aggregate_data(cls_drop_files):\n",
    "    \"\"\"\n",
    "    Load all stats.csv files and aggregate into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        cls_drop_files: List of tuples (cls_drop_string, file_path)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with aggregated data\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for cls_drop_str, file_path in cls_drop_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['cls_drop'] = cls_drop_str\n",
    "            all_data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read {file_path}: {e}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(\"No valid stats.csv files found!\")\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def create_metric_table(df, qmia_metric, baseline_metric, metric_name):\n",
    "    \"\"\"\n",
    "    Create a table for a specific metric showing QMIA and Baseline values.\n",
    "    \n",
    "    Args:\n",
    "        df: Aggregated DataFrame\n",
    "        qmia_metric: Column name for QMIA metric\n",
    "        baseline_metric: Column name for Baseline metric\n",
    "        metric_name: Human-readable metric name\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with the metric table\n",
    "    \"\"\"\n",
    "    # Pivot table with cls_drop as columns and dataset_type as rows\n",
    "    qmia_table = df.pivot(index='dataset_type', columns='cls_drop', values=qmia_metric)\n",
    "    baseline_table = df.pivot(index='dataset_type', columns='cls_drop', values=baseline_metric)\n",
    "    \n",
    "    # Create multi-level columns\n",
    "    qmia_cols = pd.MultiIndex.from_product([['QMIA'], qmia_table.columns], \n",
    "                                           names=['Method', 'cls_drop'])\n",
    "    baseline_cols = pd.MultiIndex.from_product([['Baseline'], baseline_table.columns], \n",
    "                                               names=['Method', 'cls_drop'])\n",
    "    \n",
    "    qmia_table.columns = qmia_cols\n",
    "    baseline_table.columns = baseline_cols\n",
    "    \n",
    "    # Combine tables\n",
    "    result_table = pd.concat([qmia_table, baseline_table], axis=1)\n",
    "    \n",
    "    # Sort columns by cls_drop numbers within each method\n",
    "    result_table = result_table.reindex(sorted(result_table.columns, key=lambda x: [int(n) for n in x[1].split(',')]), axis=1)\n",
    "    \n",
    "    return result_table\n",
    "\n",
    "def format_table_for_display(table, metric_name):\n",
    "    \"\"\"Format table with proper rounding and add a title.\"\"\"\n",
    "    # Round to 4 decimal places for readability\n",
    "    formatted_table = table.round(4)\n",
    "    \n",
    "    # Add a descriptive name\n",
    "    formatted_table.index.name = 'Dataset Type'\n",
    "    \n",
    "    return formatted_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stats files for base_cifar20 with cifar-vit...\n",
      "Found 19 stats files:\n",
      "  cls_drop_0: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_0/predictions/stats.csv\n",
      "  cls_drop_1: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_1/predictions/stats.csv\n",
      "  cls_drop_01: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_01/predictions/stats.csv\n",
      "  cls_drop_2: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_2/predictions/stats.csv\n",
      "  cls_drop_3: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_3/predictions/stats.csv\n",
      "  cls_drop_4: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_4/predictions/stats.csv\n",
      "  cls_drop_5: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_5/predictions/stats.csv\n",
      "  cls_drop_6: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_6/predictions/stats.csv\n",
      "  cls_drop_7: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_7/predictions/stats.csv\n",
      "  cls_drop_8: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_8/predictions/stats.csv\n",
      "  cls_drop_9: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_9/predictions/stats.csv\n",
      "  cls_drop_23: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_23/predictions/stats.csv\n",
      "  cls_drop_45: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_45/predictions/stats.csv\n",
      "  cls_drop_67: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_67/predictions/stats.csv\n",
      "  cls_drop_89: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_89/predictions/stats.csv\n",
      "  cls_drop_01234: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_01234/predictions/stats.csv\n",
      "  cls_drop_56789: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_56789/predictions/stats.csv\n",
      "  cls_drop_0123456789: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_0123456789/predictions/stats.csv\n",
      "  cls_drop_10111213141516171819: ../models/mia/base_cifar20/0_16/cifar-vit/attack_cifar20/0_16/facebook/convnext-tiny-224/score_fn_top_two_margin/loss_fn_gaussian/cls_drop_10111213141516171819/predictions/stats.csv\n",
      "\n",
      "Loading and aggregating data...\n",
      "\n",
      "Creating AUC table...\n",
      "\n",
      "Creating TPR_at_1pct_FPR table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1239867/2295731811.py:61: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  stacked_table = table.loc[['in_distribution']].stack(level='Method').reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls_drop</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>01</th>\n",
       "      <th>23</th>\n",
       "      <th>45</th>\n",
       "      <th>67</th>\n",
       "      <th>89</th>\n",
       "      <th>01234</th>\n",
       "      <th>56789</th>\n",
       "      <th>0123456789</th>\n",
       "      <th>10111213141516171819</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_type</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">in_distribution</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMIA</th>\n",
       "      <td>0.665</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cls_drop                      0      1      2      3      4      5      6  \\\n",
       "dataset_type    Method                                                      \n",
       "in_distribution Baseline  0.660  0.656  0.663  0.658  0.661  0.659  0.659   \n",
       "                QMIA      0.665  0.656  0.662  0.661  0.665  0.660  0.661   \n",
       "\n",
       "cls_drop                      7      8      9     01     23     45     67  \\\n",
       "dataset_type    Method                                                      \n",
       "in_distribution Baseline  0.658  0.659  0.660  0.657  0.661  0.661  0.658   \n",
       "                QMIA      0.663  0.659  0.663  0.659  0.662  0.661  0.660   \n",
       "\n",
       "cls_drop                     89  01234  56789  0123456789  \\\n",
       "dataset_type    Method                                      \n",
       "in_distribution Baseline  0.660  0.661  0.658       0.661   \n",
       "                QMIA      0.661  0.665  0.660       0.665   \n",
       "\n",
       "cls_drop                  10111213141516171819  \n",
       "dataset_type    Method                          \n",
       "in_distribution Baseline                 0.658  \n",
       "                QMIA                     0.662  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1239867/2295731811.py:61: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  stacked_table = table.loc[['in_distribution']].stack(level='Method').reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls_drop</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>01</th>\n",
       "      <th>23</th>\n",
       "      <th>45</th>\n",
       "      <th>67</th>\n",
       "      <th>89</th>\n",
       "      <th>01234</th>\n",
       "      <th>56789</th>\n",
       "      <th>0123456789</th>\n",
       "      <th>10111213141516171819</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_type</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">in_distribution</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>1.10</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMIA</th>\n",
       "      <td>3.38</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cls_drop                     0     1     2     3     4     5     6     7  \\\n",
       "dataset_type    Method                                                     \n",
       "in_distribution Baseline  1.10  1.12  1.08  1.14  1.14  1.13  1.11  1.12   \n",
       "                QMIA      3.38  3.39  3.48  3.09  3.36  3.19  3.12  3.50   \n",
       "\n",
       "cls_drop                     8     9    01    23    45    67    89  01234  \\\n",
       "dataset_type    Method                                                      \n",
       "in_distribution Baseline  1.08  1.17  1.06  1.10  1.11  1.08  1.11   1.11   \n",
       "                QMIA      3.26  3.17  3.60  2.93  3.36  3.07  3.10   3.24   \n",
       "\n",
       "cls_drop                  56789  0123456789  10111213141516171819  \n",
       "dataset_type    Method                                             \n",
       "in_distribution Baseline   1.09        1.14                  1.12  \n",
       "                QMIA       3.00        3.20                  3.17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = type('Args', (), {\n",
    "    'base_dataset': 'base_cifar20',\n",
    "    'base_model': 'cifar-vit',\n",
    "    'models_dir': '../models',\n",
    "    'output_dir': '../rebuttal_outputs'\n",
    "})()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(args.output_dir)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Find all stats files for the given dataset and model\n",
    "print(f\"Finding stats files for {args.base_dataset} with {args.base_model}...\")\n",
    "cls_drop_files = find_stats_files(args.base_dataset, args.base_model, args.models_dir)\n",
    "\n",
    "if not cls_drop_files:\n",
    "    print(f\"No stats.csv files found for {args.base_dataset}/{args.base_model}\")\n",
    "\n",
    "print(f\"Found {len(cls_drop_files)} stats files:\")\n",
    "for cls_drop_num, file_path in cls_drop_files:\n",
    "    print(f\"  cls_drop_{cls_drop_num}: {file_path}\")\n",
    "\n",
    "# Load and aggregate data\n",
    "print(\"\\nLoading and aggregating data...\")\n",
    "df = load_and_aggregate_data(cls_drop_files)\n",
    "\n",
    "# Create output filename prefix\n",
    "output_prefix = f\"{args.base_dataset}_{args.base_model.replace('-', '_')}\"\n",
    "\n",
    "# Create the three metric tables\n",
    "metrics = [\n",
    "    ('qmia_auc', 'baseline_auc', 'AUC'),\n",
    "    ('qmia_tpr_at_fpr_1%', 'baseline_tpr_at_fpr_1%', 'TPR_at_1pct_FPR'),\n",
    "    # ('qmia_tpr_at_fpr_0.1%', 'baseline_tpr_at_fpr_0.1%', 'TPR_at_0.1pct_FPR')\n",
    "]\n",
    "\n",
    "tables = []\n",
    "\n",
    "for qmia_metric, baseline_metric, metric_name in metrics:\n",
    "    print(f\"\\nCreating {metric_name} table...\")\n",
    "    \n",
    "    # Create the table\n",
    "    table = create_metric_table(df, qmia_metric, baseline_metric, metric_name)\n",
    "    \n",
    "    # # Save to CSV\n",
    "    # output_file = output_dir / f\"{output_prefix}_{metric_name.lower()}.csv\"\n",
    "    # formatted_table.to_csv(output_file)\n",
    "    # print(f\"Saved {metric_name} table to: {output_file}\")\n",
    "\n",
    "    tables.append(table)\n",
    "\n",
    "for (qmia_metric, baseline_metric, metric_name), table in zip(metrics, tables):\n",
    "    if \"TPR\" in metric_name:\n",
    "        table *= 100\n",
    "        table[numeric_cols] = table[numeric_cols].round(2)\n",
    "    else:\n",
    "        table = table.round(3)\n",
    "    numeric_cols = table.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Stack Method annotations as rows\n",
    "    stacked_table = table.loc[['in_distribution']].stack(level='Method').reset_index()\n",
    "    stacked_table = stacked_table.rename(columns={'level_1': 'Method'})\n",
    "    stacked_table = stacked_table.set_index(['dataset_type', 'Method'])\n",
    "    \n",
    "    # Define the desired column order\n",
    "    col_order = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "                 '01', '23', '45', '67', '89', '01234', '56789', \n",
    "                 '0123456789', '10111213141516171819']\n",
    "    \n",
    "    # Reorder columns, keeping dataset_type and Method as index\n",
    "    stacked_table = stacked_table.reindex(columns=col_order)\n",
    "    display(stacked_table)\n",
    "\n",
    "# # Save raw aggregated data as well\n",
    "# raw_output_file = output_dir / f\"{output_prefix}_raw_data.csv\"\n",
    "# df.to_csv(raw_output_file, index=False)\n",
    "# print(f\"\\nSaved raw aggregated data to: {raw_output_file}\")\n",
    "\n",
    "# print(f\"\\nAll outputs saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
